\documentclass[12pt]{article}
\usepackage[francais]{babel}
\usepackage[latin1]{inputenc}
%\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{times}
\usepackage[dvips]{graphicx}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{float}
\usepackage{makeidx}
\usepackage{amsfonts,dsfont}
\usepackage{listings}
\usepackage{textcomp}
\usepackage{lmodern} 
\usepackage{makeidx}
\usepackage{xcolor}
\usepackage{color}
\usepackage{multicol}
\usepackage{todonotes}
\lstset{language=Python,commentstyle=\color{gray},literate=
	{²}{{\textsuperscript{2}}}1
	{?}{{\textsuperscript{4}}}1
	{?}{{\textsuperscript{6}}}1
	{?}{{\textsuperscript{8}}}1
	{é}{{\'e}}1
	{è}{{\`{e}}}1
	{ê}{{\^{e}}}1
	{É}{{\'{E}}}1
	{Ê}{{\^{E}}}1
	{û}{{\^{u}}}1
	{ù}{{\`{u}}}1
	{â}{{\^{a}}}1
	{à}{{\`{a}}}1
	{á}{{\'{a}}}1
	{ã}{{\~{a}}}1
	{Á}{{\'{A}}}1
	{Â}{{\^{A}}}1
	{Ã}{{\~{A}}}1
	{ç}{{\c{c}}}1
	{Ç}{{\c{C}}}1
	{õ}{{\~{o}}}1
	{ó}{{\'{o}}}1
	{ô}{{\^{o}}}1
	{Õ}{{\~{O}}}1
	{Ó}{{\'{O}}}1
	{Ô}{{\^{O}}}1
	{î}{{\^{i}}}1
	{Î}{{\^{I}}}1
	{í}{{\'{i}}}1
	{Í}{{\~{Í}}}1,keywordstyle=\color{red},stringstyle=\color{blue},morekeywords={plt,np},breaklines=true}

\textwidth=18cm \textheight=23cm \oddsidemargin=-1.00cm
\evensidemargin=-1.00cm
\parindent=1cm
\topmargin=-2cm

\begin{document}
	
	
	\begin{center}
		
		{\large{\bf ECOLE NATIONALE DES PONTS ET CHAUSSEES}}
		
		\medskip
		
		\begin{figure}[H]
			\centering
			\includegraphics[width=4cm]{logoenpc}
		\end{figure}
		
		
		
		{\large{\bf PROJET D'INITIATION A LA RECHERCHE 2018}}
		
		\vspace{2cm}
		
		{\Large{\bf Réduction de modèles appliquée à la modélisation du transport de polluants}}
		
		\vspace{1cm}
		
		{\large{Léo Baty, Clément Lasuen, Chiheb Eddine Najjar,\\ Nathan Godey, Régis Santet, Song Phuc Duong \\ sous la direction de \\ Damiano Lombardi, Sébastien Boyaval \\ Laboratoire INRIA}}
		
		\vspace{2cm}
		
		\newpage
		
		\tableofcontents
		
		\newpage
		
		\begin{minipage}{16cm}
			{\normalsize
				\parindent=0pt
				{{\bf ABSTRACT} : The ability of predicting the behaviour of a pollutant in a fluid is crucial in several realistic applications, such as when a drilling rig explodes undersea (\emph{Deepwater Horizon} explosion in 2010 for example). Despite the increasing available computational power, the number of the parameters in the system and the number of degrees of freedom needed to approximate its solution make the prediction task prohibitively expensive from a computational point of view.. We have to use reduction models such as POD (Proper Orthogonal Decomposition) in order to compute the solution in a reasonable time. It involves keeping the major dynamic of the solution with a few degrees of freedom and accepting an error between the approximation and the real solution.
					We use the advection equation to simulate a pollution peak represented by a Gaussian function in a fluid where the fluid speed varies in a closed region. After computing a couple of solutions using our initial integration schemes for some parameters like the finite volumes scheme and explicit Euler scheme to simulate the fundamental dynamic, we use the POD algorithm to compute approximate solutions for a new set of parameters, this time in a much shorter period. We decided to approach the problem with two different methods. The Eulerian method, in which we consider the velocity as a function of space and time, and try to compute the concentration of the pollutant as a function of the same variables. Whereas in the Lagrangian method, we follow some particles arraigned initially in a random way according to a probability law adapted to the initial concentration and compute their trajectory as a function of time and the initial location. Thus, we will try to compare both methods to see which one suits the problem better.
				}
				\par}
		\end{minipage}
		
		\vspace{1cm}
		
		\begin{minipage}{16cm}
			{\normalsize
				\parindent=0pt
				{{\bf KEYWORDS} : Mathematical Models, Numerical Simulations, Computational Complexity, Model Order Reduction, Proper Orthogonal Decomposition, Singular Value Decomposition}
				\par}
		\end{minipage}
		
	\end{center}
	
	\newpage
	
	\bibliographystyle{unsrt}
	
	\section{Introduction}
	
	Le but de ce projet d'initiation à la recherche est d'observer numériquement l'évolution d'une concentration de polluants (fluide que l'on considère incompressible) dans un liquide (rejets dans une rivière) ou dans un gaz (nuage radioactif). Ce projet est associé au cours intitulé "Méthodes numériques pour les problèmes en grandes dimensions" ~\cite{Cours1} tenu en première année à l'École nationale des ponts et chaussées par Damiano Lombardi (INRIA) et Sébastien Boyaval (INRIA). Nous allons donc chercher à utiliser des outils de réductions de modèles afin de pouvoir prédire, étant donné une concentration initiale de polluant en un lieu donné, l'évolution de la concentration de façon fiable.
	La dynamique de la solution réelle dépend d'un nombre de paramètres beaucoup trop grand si l'on souhaite la simuler tout le temps avec des paramètres différents à chaque fois (position initiale, champs de vitesse,...). La discrétisation du problème pose aussi problème, avec un phénomène de diffusion souvent inévitable. Le but de la méthode de réduction de modèles est de pouvoir se ramener à une base de solutions qui contiennent en elle-même la majeure partie de la dynamique de la solution réelle pour un certain nombre de paramètres où on aura la solution fine, afin de pouvoir simuler de façon approchée et surtout plus rapide des nouveaux schémas avec des paramètres différents.\\
	Il faut donc d'abord penser à l'approche que l'on va avoir sur la discrétisation du problème, puis savoir quel outil de la réduction de modèle utiliser afin d'avoir une erreur relativement faible pour un temps relativement court : un compris est donc fait entre temps de calcul et précision.
	
	
	\section{Matériels et méthodes}
	
	Tout notre projet repose sur l'équation dite d'\emph{advection}, ou de \emph{transport de matière} :
	
	\begin{equation}
	\partial_tc+u\nabla c=0.
	\label{equation1}
	\end{equation}
	
	où $c$ est la concentration de polluant et $u$ est le champs de vitesse présent dans le liquide ou le gaz. Pour une simulation numérique, nous devons nous munir d'un code donnant un maillage de la zone que nous voulons étudier, d'un schéma de discrétisation en temps et en espace de l'équation (\ref{equation1}), et d'une condition initiale. 
	
	Une fois ce code mis en place, nous utilisons l'algorithme POD (Proper Orthogonal Decomposition) pour réduire notre solution. Nous nous posons alors trois questions :
	\begin{itemize}
		\item L'algorithme POD est-il adapté à l'équation d'advection ? 
		\item Quelle approche, lagrangienne ou eulérienne, convient-il de prendre ?
		\item Peut-on trouver un moyen d'augmenter la compression de données ?
	\end{itemize}
	
	Nous allons explorer ces questions à travers deux exemples : un écoulement à vitesse constant (où juste l'angle d'incidence change) et un écoulement cellulaire (des tourbillons).\\
	
	\subsection{Méthode POD : \emph{Proper Orthogonal Decomposition}}
	
	L'inconnue du problème est notée $C(t) \in \mathbb{R}^N$ pour $(t,x) \in [0,T]$. La première étape de cette méthode consiste à calculer des valeurs de la solution $X(t_0), X(t_1), ..., X(t_n)$ à des instants $t_0, t_1, ... t_n$, appelées snapshots. Ces vecteurs sont ensuite classés dans une matrice M : 
	$$ M =
	\begin{pmatrix}
	C(t_0) & | & C(t_1) &| & \cdots & | & C(t_n)
	\end{pmatrix}
	$$
	où : $C(t_i)_j = c(x_j,t_i)$. $(x_j)_ {1 \leqslant j \leqslant N}$ sont les points où la solution $c$ du problème de transport est calculée précisement.
	La décomposition SVD (Singular Value Decomposition) de la matrice $M$ s'écrit : $ M = USV^T $ où $U$ et $V$ sont des matrices orthogonales respectivement de taille $N$ et $n$. La matrice $S$ est diagonale, ses coefficients sont les valeurs singulières de $M$ (les valeurs propres de $M^TM$). Cette décomposition est unique lorsque les coefficients sur la diagonale de $S$, notés $\sigma_1,...,\sigma_p$ avec $p = rang(S) =rang(M)$, sont ordonnés par ordre décroissant.
	
	Les colonnes de $U$, notées $U^{(1)},..., U^{(N)}$ sont les modes propres de la matrice (ce sont les vecteurs propres de $M^TM$).
	Soit $r$ un entier compris entre 1 et le rang de $S$. Les vecteurs $U^{(1)},..., U^{(r)}$ forment alors une 
	base orthonormée d'un sous-espace vectoriel de $\mathbb{R}^N$ dans lequel on projette la dynamique du système. 
	
	Cette méthode s'applique lorsque la dynamique du système reste proche d'un sous-espace vectoriel de dimension faible. Cela correspond à une décroissance rapide des valeurs singulières de $M$. L'erreur de représentation est donnée par : $\sum_{i=r+1}^p \sigma_i^2$.
	On obtient ainsi une representation simple de la solution. Cela nous permet ensuite de faire varier les paramètres du modèle ainsi que le champs de vitesse.
	
	\subsection{Paramétrage}
	
	Dans tout ce qui suit, nous avons opté comme maillage un quadrillage de la zone $(0,1)^2$, et le nombre de cases sur le maillage est égal à $(2\times10^{8}+1)^2$ : c'est un cas où le maillage est plutôt fin et le temps de calcul, bien qu'un peu long, reste raisonnable.\\
	
	On effectue un nombre $n_s$ de simulations différentes dans chaque cas afin de pouvoir remplir la matrice qui va nous servir pour faire l'algorithme POD (matrice contenant quelques solutions fines du problème).\\
	On prend un temps maximal de simulation égal à $T_{max}=1$.\\
	Lors de l'algorithme POD, on se fixe un nombre $nb_{modes}$ que l'on choisit tel que l'erreur sur la solution soit satisfaisante. Cette erreur est choisie a posteriori, étant un compromis entre le temps de calcul (nombre de modes) et l'erreur de la précision de l'algorithme.
	
	\paragraph{Cas d'une vitesse constante}
	
	Dans le cas où la vitesse est constante, seule sa direction varie et est donnée par un angle $\theta\in[0,\frac{\pi}{2}]$ (on prend ces angles pour éviter que l'on n'atteigne le bord). On a donc
	
	$$\left\{\begin{array}{c c c}
	u_x = ||u||\cos(\theta)\\
	u_y = ||u||\sin(\theta)
	\end{array}\right.$$	
	
	Les particules sont distribuées selon une gaussienne centrée en (0.25 ; 0.25) de variance 1/50. Leurs vitesses sont identiques, constante et orientées avec un angle $\theta$ compris entre $0$ et $\frac{\pi}{2}$.
	
	\paragraph{Cas d'un écoulement cellulaire}
	
	Dans ce cas, le champ de vitesse dérive du potentiel suivant : 
	$$\psi(x,y) = \sin(2\pi x) \sin(2\pi y) + \theta_0 \cos(2\pi\theta_1x)\cos(2\pi \theta_2y)$$
	où $\theta_0 \in [0,2.5]$ et $(\theta_1,\theta_2) \in [0.5,4]^2$. Nous avons pris $\theta_1=\theta_2=\frac{1}{2}$.
	La vitesse s'exprime alors : 
	
	$$
	\left\{
	\begin{array}{c c c}
	u_x(x,y) = \frac{\partial \psi}{\partial y} = 2\pi \sin(2\pi x) \cos(2\pi y) - \theta_0 2\pi \theta_2 \cos(2\pi \theta_1x)\sin(2\pi \theta_2y)\\
	u_y(x,y) = -\frac{\partial \psi}{\partial x} = -2\pi \sin(2\pi y) \cos(2\pi x) + \theta_0 2\pi \theta_1 \cos(2\pi \theta_2y)\sin(2\pi \theta_1x)
	\end{array}
	\right.
	$$ 
	
	\paragraph{Champ de vitesse de Lamb-Oseen}
	
	Nous prenons dans ce cas une vitesse analytique donnée par : 
	$$ \mathbf{V}(r,\theta,t) = \frac{\Gamma}{2\pi r}\left(1 - \exp\left( \frac{-r^2}{4\nu t + r_c^2}\right)\right)\mathbf{u_{\theta}}$$
	
	où $\nu$ désigne la viscosité cinématique, $\Gamma$ est la circulation de l'écoulement et $r_c$ le rayon moyen.
	
	
	\subsection{Approche Eulérienne}
	
	\subsubsection{Description}
	
	L'approche Eulérienne consiste à déterminer en chaque point de notre maillage les valeurs de la concentration en polluant. On va donc, à chaque itération de l'algorithme, mettre à jour l'ensemble du maillage.\\
	
	Il se trouve qu'une simple approche par la méthode des différences finies n'est pas un schéma stable pour notre étude : le schéma est un peu trop instable (concentration pouvant devenir négative). On va lui préférer la méthode des volumes finis avec un schéma de Lax-Friedrichs, qui est un schéma qui assure, par exemple, la positivité (et qui donc respecte une des propriétés fondamentales de la solution du problème continu). Ce schéma numérique classique introduit de la diffusion numérique. Les paramètres de discretisation seront donc choisis afin de limiter ce phénomène. Pour plus de détails, voir la section \ref{volumesfinis}.\\
	
	Nous avions à notre disposition un code d'éléments finis 2D sous Scilab faisant tourner le schéma de Lax-Friedrichs sur des cas très génériques et un maillage uniforme sur $(0,1)^2$. En déchiffrant une partie de ce code, et en s'y inspirant, nous avons codé ce schéma en Python, de façon simplifiée et en retenant seulement ce qui allait nous servir pour notre étude (maillage, fonction permettant l'actualisation, affichage de la solution). La zone étudiée est toujours $(0,1)^2$, et notre condition initiale est représentée par une gaussienne étroite (équivalente à un pic de polluant). De plus, les conditions aux bords sont périodiques : nous nous plaçons sur une sphère afin de rendre le code plus simple, même si nous ferons en sorte de ne jamais atteindre les bords. Ce code Python est donné en annexe.\\
	
	
	
	Notre condition initiale est donnée par une gaussienne :
	$$c_0(x,y)=\exp \left(-\frac{(x-x_0)^2+(y-y_0)^2}{2\sigma ^2} \right)$$
	
	avec $(x_0,y_0)=(0.25,0.25)~,~\sigma =\frac{1}{50}$.
	L'approche eulérienne consiste donc à transporter cette gaussienne le long du maillage. 
	
	\begin{tabular}{cc}
		\includegraphics[width=0.5\linewidth]{euler_condition_initiale} &	\includegraphics[width=0.5\linewidth]{euler_condition_initiale_simulee}\\
		Condition initiale... & ...et après un certain temps
	\end{tabular}
	
	On stocke les valeurs de la solution au cours du temps sur tout le maillage dans une matrice à laquelle on va appliquer l'algorithme POD. Après un choix adapté du nombre de modes, on va pouvoir simuler la dynamique de notre système avec un nombre de degré de libertés bien plus faible.	
	
	
	
	\subsubsection{Méthode des volumes finis}\label{volumesfinis}
	
	% faire un condense de cette méthode, récupérer les équations importantes en négligeant les détails qui seront dans l'appendice
	
	Le but de cette méthode est d'implémenter un schéma qui permet d'approcher la solution faible de l'équation : 
	\begin{equation}
	\frac{\partial c}{\partial t} + \mathrm{div}(c \ u) = 0 
	\label{eq}
	\end{equation}
	de manière à assurer la convergence et la stabilité (voir le paragraphe Critères de convergence et de stabilité).
	
	Nous regardons cette équation dans un compact en temps et en espace $[0,T] \times [0,L]^2$. Pour cela nous considèrerons un maillage en espace rectangulaire uniforme $K_{i,j}$ de pas $\Delta x$, $\Delta y$, et un maillage en temps de pas $\Delta t_n$ qui dépend \textit{a priori} de l'instant $t_n$. La méthode des volumes finis cherche à exprimer la valeur moyenne de la concentration $c$ sur chaque cellule $K_{i,j}$ en fonction de la valeur moyenne cellulaire de la vitesse et des différents paramètres du maillage à savoir le pas et le volume des cellules. En d'autres termes, on exprime : 
	\[
	c_{i,j}(t_n) =\frac{1}{\vert K_{i,j} \vert}\int_{K_{i,j}} c(t_n,X) dX
	\]
	en fonction de $u_{i,j}(t_n)$, $\Delta x$, $\Delta y$ et $\Delta t_n$. Pour cela, nous intégrons l'équation (\ref{eq}) sur la cellule $K_{i,j}$ à l'instant $t_n$. Nous obtenons :
	\[
	\frac{\partial c_{i,j}}{\partial t}(t_n) +  \frac{1}{\vert K_{i,j} \vert} \int_{\partial K_{i,j} } c \ u \cdot n \ dL = 0\\
	\]
	Nous approchons la dérivée temporelle par un schéma d'Euler explicite et le flux par un schéma de Lax-Friedrichs :\\
	Pour toute cellule $K_{i,j}$
	\begin{equation}
	c_{i,j}(t_n) = c_{i,j}(t_{n-1}) - \frac{t_n-t_{n-1}}{\vert K_{i,j} \vert}  \sum_{k,l} \vert \Gamma_{i,j}^{k,l} \vert g(c_{i,j}(t_{n-1}),c_{k,l}(t_{n-1})) \ \forall n
	\label{schema}
	\end{equation}
	où $\Gamma_{i,j}^{k,l} = K_{i,j} \cap K_{k,l}$ et :
	\begin{equation}
	\begin{cases}
	\lambda_{i,j \rightarrow k,l} = \mathrm{max}\lbrace u_{i,j}\cdot n_{i,j \rightarrow k,l} , u_{k,l}\cdot n_{i,j \rightarrow k,l} \rbrace \\
	g(c_{i,j},c_{k,l}) = \frac{1}{2} (c_{i,j}u_{i,j} + c_{k,l}u_{k,l})\cdot n_{i,j \rightarrow k,l} + \frac{1}{2\lambda_{i,j \rightarrow k,l}}(c_{i,j} - c_{k,l})
	\end{cases}
	\end{equation}
	à l'instant $t_n$.
	Pour plus de détails voir la section (\ref{MVF-A}).
	\paragraph{Critères de convergence et de stabilité}
	Lorsque l'on part d'une condition initiale bornée, l'équation dans le sens faible (\ref{eq}) admet une unique solution entropique, c'est à dire la solution vérifie : $\forall S \in \mathcal{C}^2$ convexe, on a 
	\[
	\frac{\partial S(c)}{\partial t} + \mathrm{div}(G(c)) \leq 0
	\]
	où $G$ est un flux d'entropie qui vérifie $G^{'} = S^{'} u$.\\
	
	Le schéma numérique (\ref{schema}) converge vers cette solution (lorsque $\Delta x,\Delta y, \Delta t_n \longrightarrow 0$) dès qu'il vérifie l'inégalité entropique discrétisée : $\forall S \in \mathcal{C}^2$ convexe, $\exists \Phi(c_1,c_2)$ telle que 
	\begin{equation}
	\begin{cases}
	\Phi(c,c) = G(c) \\
	\frac{S(c_{i,j}(t_n))-S(c_{i,j}(t_{n-1}))}{t_n-t_{n-1}} + \sum_{k,l} \frac{\vert \Gamma_{i,j}^{k,l} \vert}{\vert K_{i,j} \vert} \Phi(c_{i,j}(t_{n-1}),c_{k,l}(t_{n-1})) \leq 0 \ \ \forall i,j,n
	\end{cases}
	\end{equation}
	Ainsi, l'entropie doit être dissipée ou conservée, son augmentation est une source d'instabilité du schéma.
	
	Pour que le schéma des volumes finis (\ref{schema}) soit stable, il faut satisfaire la condition CFL (Courant, Friedrichs, Lewy) qui s'écrit :
	\[
	t_n - t_{n-1} < \frac{\vert K_{i,j} \vert}{2\vert \Gamma_{i,j}^{k,l} \vert \lambda_{i,j \rightarrow k,l}(t_{n-1})} \ \ \forall i,j,k,l
	\]
	
	Cette condition nous permet de choisir le pas de temps adapté à la vitesse et à la géométrie du maillage à chaque instant pour assurer la stabilité.
	
	\subsubsection{Modèle Réduit}
	La POD fournit une base orthonormée de $r$ fonctions scalaires $(P^k)_{k=1}^r$ discrétisées en espace 2D, on note $P^k_{i,j}$ la valeur moyenne de $P^k$ dans la cellule $K_{i,j}$.\\
	
	Nous allons approcher la concentration $c$ en utilisant cette base. Ainsi on note :
	\begin{equation}
	c(X,t) \simeq c^r(X,t) = \sum_{k=1}^r a_k(t) P^k(X)
	\label{MR-C}
	\end{equation}
	
	On injecte \eqref{MR-C} dans \eqref{equation1}, on obtient : 
	
	\begin{align*}
	& \partial_t \left( \sum_{k=1}^r a_k P^k \right) + u \cdot \nabla \left( \sum_{k=1}^r a_k P^k \right) = 0 \\
	\Rightarrow & \ \ \sum_{k=1}^r \partial_t a_k P^k + \sum_{k=1}^r  a_k u \cdot \nabla  P^k  = 0 \\
	\Rightarrow & \ \ \forall \ 1\leq k_0 \leq r \ \ \sum_{k=1}^r \partial_t a_k \langle P^k,P^{k_0} \rangle + \sum_{k=1}^r  a_k \langle u \cdot \nabla  P^k, P^{k_0} \rangle = 0 
	\end{align*} 
	avec $\langle f , g \rangle = \int_{[0,1]^2} fg$, qui est le produit scalaire de $L^2$. Comme la base $(P^k)_{k=1}^r$ est orthonormée, on obtient :
	$$
	\forall \ 1\leq k_0 \leq r \ \ \partial_t a_{k_0} + \sum_{k=1}^r  a_k \langle u \cdot \nabla  P^k, P^{k_0} \rangle = 0 
	$$
	Ainsi on construit une matrice $D$ de dimension $r \times r$ telle que $[D]_{l,k} = \langle u \cdot \nabla  P^k, P^{l} \rangle $ et un vecteur $A(t)$ de dimension $r$ tel que $[A(t)]_k = a_k(t)$, et par suite l'équation devient :
	\begin{equation}
	\partial_t A(t) + D \cdot A(t) = 0
	\label{MR}
	\end{equation}
	
	\paragraph{Discrétisation spatiale et calcul de $D$ :}
	
	Toute fonction $P^k$ est discrétisée en espace de la façon suivante : 
	$$
	P_{i,j}^k = \frac{1}{\vert K_{i,j} \vert} \int_{K_{i,j}}
	P^k(X) \mathrm{d}X
	$$
	D'abord, on essaye d'approcher $\nabla P^k$ sur $K_{i,j}$ en utilisant un schéma de différences finis :
	$$
	\nabla P^k_{i,j} =
	\begin{pmatrix}
	\frac{P^k_{i,j+1}-P^k_{i,j-1}}{2\Delta x} \\
	\frac{P^k_{i+1,j}-P^k_{i-1,j}}{2\Delta y}
	\end{pmatrix}
	$$
	ainsi :
	$$
	(u \cdot \nabla P^k )_{i,j} = u^x_{i,j} \frac{P^k_{i,j+1}-P^k_{i,j-1}}{2\Delta x} + u^y_{i,j} \frac{P^k_{i+1,j}-P^k_{i-1,j}}{2\Delta y}
	$$
	et finalement on peut calculer les coefficients de $D$
	\begin{align*}
	[D]_{l,k} &= \int_{[0,1]^2} (u \cdot \nabla P^k) \ P^l\\
	&\simeq \sum_{i,j} \vert K_{i,j} \vert (u \cdot \nabla P^k )_{i,j} \ P^l_{i,j} \\
	&= \sum_{i,j} \vert K_{i,j} \vert  \left(u^x_{i,j} \frac{P^k_{i,j+1}-P^k_{i,j-1}}{2\Delta x} + u^y_{i,j} \frac{P^k_{i+1,j}-P^k_{i-1,j}}{2\Delta y} \right) \ P^l_{i,j}  \ \ \ \forall 1 \leq k,l \leq r
	\end{align*}
	\paragraph{Discrétisation temporelle :} Nous utilisons le schéma d'Euler implicite pour discrétiser en temps l'équation \eqref{MR} qui s'écrit :
	$$
	\frac{1}{t_n - t_{n-1}}(A(t_n)-A(t_{n-1})) + D \cdot A(t_n) = 0
	$$
	ou en réarrangeant les termes :
	\begin{equation}
	A(t_n) = A(t_{n-1}) - \Delta t_n D \cdot A(t_n)
	\end{equation}
	
	\paragraph{Condition initiale}
	Posons $C(t_n)$ le vecteur qui contient les $c_{i,j}(t_n)$ et $C_r$ le vecteur contient les $c^r_{i,j}(t_n)$. On remarque alors que $C_r(t_n)$ ( de dimension $n_x \times n_y$) est complètement déterminé par le vecteur $A(t_n)$ (de dimension $r$) via l'équation :
	$$
	C(t_n) \simeq C_r(t_n) = U_r \cdot A(t_n)
	$$	
	où 
	$$
	U_r = (P^1 \vert P^2 \vert \dots P^r)
	$$
	Pour déterminer la condition initiale $A(t_0)$, il suffit de projeter la condition initiale $C(t_0)$ sur la base $(P^k)$, cela revient à :
	$$
	A(t_0) = U_r^T \cdot C(t_0)
	$$
	\paragraph{Algorithme :}
	On part de la condition initiale $A(t_0) = U_r^T \cdot C(t_0)$ puis pour $n>0, t_n<T$ on résout l'équation 
	$(\Delta t_n D + I_r) \cdot A(t_n) = A(t_{n-1})$. Les vecteurs $A(t_n)$ ainsi obtenus sont utilisés pour reconstruire
	les vecteurs $C(t_n)$ avec la relation $C(t_n) = U_r \cdot A(t_n)$.\\
	
	On voit ici l'intérêt de la méthode POD, on a pu réduire le problème de dimension ($n_x \times n_y \times n_t$) 
	en un problème de dimension ($r \times n_t$). Dans le cas où $r<<n_x\times n_y$, le temps de calcul est donc conséquemment réduit.
	
	\paragraph{Conditions de stabilité}
	condition CFL ...
	
	
	
	
	
	
	
	
	
	\subsection{Approche Lagrangienne}
	
	\subsubsection{Description}
	L'approche lagrangienne consiste à suivre les particules le long de leur trajectoires. Si l'on note $X(\xi,t) \in \mathbb{R}^{n\times2}$ les positions, à l'instant $t\in [0,T]$, des particules 
	qui était initialement aux positions $\xi \in \mathbb{R}^{n\times2}$, cela revient à résoudre : 
	$$
	\left\{
	\begin{array}{c c c}
	\partial_tX  =  v(X(\xi,t),t)\\
	X(\xi,0)  =  \xi
	\end{array}
	\right.
	$$ 
	
	Supposons $u \in \mathcal{C}^0(\mathbb{R}^{n\times2} \times \mathbb{R}) \bigcap W^{1,\infty}(\mathbb{R}^{n\times2} \times \mathbb{R})$.
	C'est toujours le cas dans notre étude. Alors le théorème de Cauchy-Lipschitz assure l'existence et l'unicité d'une solution locale. 
	De plus, l'application est globalement lipschitzienne. Le transport est donc à vitesse finie.
	
	\subsubsection{Résolution numérique}
	Nous avons utilisé le schéma de Crank-Nicholson :
	$$X^{(k+1)} = X^{(k)} + \frac{\Delta t}{2}(v(X^{(k)},t^k) + v(X^{(k+1)},t^{k+1}))$$
	
	Nous avons utilisé une méthode du point fixe pour évaluer $X^{(k+1)}$ en connaissant $X^{(k)}$.
	Initialisation (r=0) : $$ X^{(k+1)}_0 = X^{(k)}$$
	$$X^{(k+1)}_1 = X^{(k)} + \Delta tv(X^{(k)},t^k) $$
	$$X^{(k+1)}_{r+1} = X^{(k)} + \frac{\Delta t}{2}(v(X^{(k)},t^k) + v(X^{(k+1)}_r,t^{k+1}))$$
	Et on arrête lorsque : $$||X^{(k+1)}_{r+1} - X^{(k+1)}_r||<\epsilon$$
	
	où $\epsilon$ est une erreur donnant un critère d'arrêt : on suppose qu'on est "suffisamment proche de la solution" quand l'algorithme s'arrête.
	
	\subsubsection{Interpolation}
	
	La résolution numérique du problème nécessite de connaître le champ de vitesse des particules, noté $v$.
	Cependant, le champ de vitesse n'est pas toujours connu analytiquement Par exemple, si la vitesse est mesurée expérimentalement,
	alors elle n'est connue qu'aux points de mesure. Nous présentons ici une méthode d'interpolation, c'est à dire qui nous permet d'approximer
	le champs de vitesse sur l'ensemble du domaine lorsqu'il n'est connu qu'en certain points.
	Nous supposons que l'ensemble $\Omega=(0,1)^2 $ soit muni d'un maillage carré régulier de pas noté $\Delta x$ en abscisse et $\Delta y$ en ordonnée. Nous supposons également que le champ de vitesse est connu en tout point du maillage. Nous présentons ici la méthode d'interpolation qu'il conviendrait d'utiliser dans ce cas.
	
	Considérons une maille dont les coordonnées du coin inférieur gauche sont notées $(x^{LL},y^{LL})$.
	Soit un point $(x,y)$ appartenant à cette maille. On pose :
	
	$$
	\left\{
	\begin{array}{c c c}
	\tilde{x}= \frac{x-x^{LL}}{\Delta x}\\
	\tilde{y}= \frac{y-y^{LL}}{\Delta y}
	\end{array}
	\right.
	$$ 
	
	On définit :
	
	$$
	\left\{
	\begin{array}{c c c}
	\varphi_1(\tilde{x}, \tilde{y}) = (1-\tilde{x})(1-\tilde{y})\\
	\varphi_2(\tilde{x}, \tilde{y}) = \tilde{x}(1-\tilde{y})\\
	\varphi_3(\tilde{x}, \tilde{y}) = \tilde{x}\tilde{y}\\
	\varphi_4(\tilde{x}, \tilde{y}) = (1-\tilde{x})\tilde{y}
	\end{array}
	\right.
	$$ 
	
	La vitesse au point $(x,y)$ à l'instant $t$ est alors donnée par :
	$$v(x,y,t) = v(x^{LL}, y^{LL},t) \varphi_1(\tilde{x}, \tilde{y}) + v(x^{LL} +\Delta x, y^{LL},t) \varphi_2(\tilde{x}, \tilde{y}) $$
	$$ + v(x^{LL}+\Delta x, y^{LL}+\Delta y,t) \varphi_3(\tilde{x}, \tilde{y}) $$
	$$ + v(x^{LL}, y^{LL}+\Delta y,t) \varphi_4(\tilde{x}, \tilde{y}) $$
	
	
	\section{Résultats}
	
	\subsection{Approche Eulerienne}
	
	\subsubsection{Cas vitesse constante}
	On effectue $n_s=16$ simulations, avec des valeurs d'angles uniformément réparties dans $[0,\frac{\pi}{2}]$.\\
	Voici d'abord le tracé du $\log$ des valeurs singulières en fonction de leur rang dans la décomposition SVD.
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.7\linewidth]{valeurs_singulieres_eulerien_constant}
		\caption{Tracé du $\log$ des valeurs singulières en fonction du rang}
		\label{fig:valeurssinguliereseulerienconstant}
	\end{figure}
	
	Ceci nous permet de choisir le nombre de modes que l'on va utiliser. Avec un nombre maximal de 50 modes (que nous nous sommes fixés),
	on voit que l'on n'arrive pas à atteindre l'erreur relative de $10^{-3}$. En fait, il faudrait environ 100 modes propres pour obtenir cette erreur là. On voit donc que l'approche eulerienne dans le cas d'une vitesse constante n'est pas optimale : en effet, pour chaque valeur de la vitesse,
	la dynamique de la solution est différente (son parcours n'est jamais le même et on ne se recoupe jamais), on ne peut donc pas facilement exhiber un sous-espace linéaire
	qui contiendrait la majorité de la dynamique. Il est donc inutile d'essayer de réduire ce modèle sous l'approche eulérienne.\\
	On note cependant qu'avec 16 simulations, on obtient une matrice de \emph{snapshots} d'environ $3,7Go$ ($257\times 257\times 8 \times 7346$, $7346$ étant le nombre de colonnes), que l'on arrive à compresser en $517ko$
	en prenant $50$ modes : même si l'erreur reste trop importante, la compression de données est très bonne grâce à l'algorithme POD.\\
	
	De plus, cet exemple illustre parfaitement le rôles des modes propres dans la reconstitution de la solution approchée. Voici en effet le tracé des modes propres sur $(0,1)^2$ (en utilisant le module \emph{pcolor} de \emph{matplotlib.pyplot}) :
	
	\begin{tabular}{cc}
		\includegraphics[width=0.5\linewidth]{eulerien_constant_mode_1} &	\includegraphics[width=0.5\linewidth]{eulerien_constant_mode_2}\\
	\end{tabular}
	
	\begin{tabular}{cc}
		\includegraphics[width=0.5\linewidth]{eulerien_constant_mode_10} &	\includegraphics[width=0.5\linewidth]{eulerien_constant_mode_50}\\
	\end{tabular}
	
	Les différentes couleurs montrent les oscillations de la fonction. On voit que le premier mode rassemble la majeure dynamique de ce qu'on a simulé : la condition initiale, qui est restée la même durant toutes nos simulations, est représentée de façon très claire.\\
	On voit ensuite, dès le deuxième mode, la première oscillation qui va permettre de reconstituer les solutions. L'oscillation se dirige dans le cadrant en haut à droite, lieu de nos simulations car $\theta \in [0,\frac{\pi}{2}]$. Le 10ème mode représente bien les différentes trajectoires de nos simulations (encore via des oscillations), et enfin, quand on va chercher des modes plus grands, on va essayer de reproduire de plus en plus les détails de la dynamique sur l'ensemble de nos valeurs de paramètres $\theta \in [0,\frac{\pi}{2}]$.\\
	
	Ensuite, nous avons testé la reconstruction d'une solution avec notre base de modes propres pour un nouveau paramètre qui ne faisait pas partie des simulations précédentes : on est donc sûr qu'aucun vecteur solution ayant servi à la POD ne peut directement représenter la solution. En l'occurrence, nous avons pris $\theta=\frac{\pi}{9}$. Ceci est un test dit \emph{out-of-data in-bound} : on utilise une valeur de paramètre non présente dans la base qui va servir à réduire la modèle, mais qui est quand même dans l'intervalle que nous nous sommes fixés au départ.\\
	
	Voici les différentes reconstructions pour un nombre de modes propres valant 10, 20, 50, 100, 200 et 500, d'abord pour la condition initiale :
	
	\begin{tabular}{cc}
		\includegraphics[width=0.5\linewidth]{eulerien_constant_reproduction_condition_initiale_10modes} &	\includegraphics[width=0.5\linewidth]{eulerien_constant_reproduction_condition_initiale_20modes}\\
		Condition initiale, 10 modes & Condition initiale, 20 modes
	\end{tabular}
	
	\begin{tabular}{cc}
		\includegraphics[width=0.5\linewidth]{eulerien_constant_reproduction_condition_initiale_50modes} &	\includegraphics[width=0.5\linewidth]{eulerien_constant_reproduction_condition_initiale_100modes}\\
		Condition initiale, 50 modes & Condition initiale, 100 modes
	\end{tabular}
	
	\begin{tabular}{cc}
		\includegraphics[width=0.5\linewidth]{eulerien_constant_reproduction_condition_initiale_200modes} &	\includegraphics[width=0.5\linewidth]{eulerien_constant_reproduction_condition_initiale_500modes}\\
		Condition initiale, 200 modes & Condition initiale, 500 modes
	\end{tabular}
	
	On voit premièrement que la condition initiale est plutôt bien restituée. Avec un nombre faibles de modes, on observe des oscillations mais elles disparaissent vite avec un nombre de modes de plus en plus grand. Cela est notamment dû au fait que la condition initiale a été la même dans toutes les simulations. On remarque aussi et surtout que la positivité de la solution n'est plus conservée après reconstruction via la base propre. C'est à contraster avec ce qu'on voulait via l'utilisation du schéma de Lax-Friedrichs.
	Regardons maintenant ce qu'il se passe à mi-parcours :
	
	\begin{tabular}{cc}
		\includegraphics[width=0.5\linewidth]{eulerien_constant_reproduction_moment_random_10modes} &	\includegraphics[width=0.5\linewidth]{eulerien_constant_reproduction_moment_random_20modes}\\
		A mi-parcours, 10 modes & A mi-parcours, 20 modes
	\end{tabular}
	
	\begin{tabular}{cc}
		\includegraphics[width=0.5\linewidth]{eulerien_constant_reproduction_moment_random_50modes} &	\includegraphics[width=0.5\linewidth]{eulerien_constant_reproduction_moment_random_100modes}\\
		A mi-parcours, 50 modes & A mi-parcours, 100 modes
	\end{tabular}
	
	\begin{tabular}{cc}
		\includegraphics[width=0.5\linewidth]{eulerien_constant_reproduction_moment_random_200modes} &	\includegraphics[width=0.5\linewidth]{eulerien_constant_reproduction_moment_random_500modes}\\
		A mi-parcours, 200 modes & A mi-parcours, 500 modes
	\end{tabular}
	
	Cette fois-ci, on voit très clairement qu'un faible nombre de modes ne permet plus de restituer une dynamique cohérente. Des oscillations de grande amplitudes sont observées pour 10 et 20 modes, et il reste encore des petites "vagues" pour 50 modes. Cependant, passé une centaine de modes, on n'observe plus de grands changements dans la gaussienne. Il faudrait donc une centaine de modes environ pour s'en sortir dans la restitution d'une solution fine pour un nouveau paramètre dans l'intervalle de départ.\\
	Si l'on fait le calcul (comme ce sera le cas pour l'écoulement cellulaire), on observe que l'erreur pour un même nombre de modes augmentent au cours du temps : cela est dû au fait que le paramètre n'est pas représenté dans la base propre dès le départ.
	
	\subsubsection{Cas des \'ecoulements cellulaires}
	
	Ensuite, nous avons consid\'er\'e le cas des \'ecoulements cellulaires (cf. param\'etrages) dans le carr\'e $[-0.5,1.5]\times [-0.5,1.5]$. On consid\`ere une condition initiale sous forme de gaussienne d'\'ecart-type $\sigma= \frac{1}{20}$ Le probl\`eme \'etant param\'etr\'e par la position initiale $(x_0,y_0)$ ainsi que par les param\`etres $(\theta_0, \theta_1, \theta_2)$, on a fix\'e $\theta_1=\theta_2=0.5$ et tir\'e al\'eatoirement de mani\`ere uniforme 64 tripl\'es $(x_0, y_0, \theta_0)$ dans $[0.25,0.75]\times [0.25,0.75]\times [0,2.5]$.

	
	\begin{figure}[H]
	\centering
	\includegraphics[width=8cm]{ecoulement_cellulaire.pdf}
	\includegraphics[width=8cm]{ecoulement_cellulaire2.pdf}
	\caption{Exemples de champs de vitesse d'\'ecoulements cellulaires pour $\theta_0=0$ et $\theta_0=2$}
	\end{figure}
	
	
	
	On a donc r\'esolu l'\'equation de transport pour ces 64 jeux de param\`etres pendant une dur\'ee $T=0.5$. On a pris un pas de maillage de $\frac{1}{2^7}$, i.e. deux fois moins fin que pour un champ de vitesse constant, sans quoi le temps de calcul aurait \'et\'e trop important. Apr\`es trois heures de simulation, on obtient une matrice $M$ des snapshots de taille $16641\times 14980$, et qui p\`ese 2 Go. 
	
	On a effectu\'e la SVD (d\'ecomposition en valeurs singuli\`eres) de $M$, puis on a sauvegard\'e les 500 premiers modes propres, pour un total de 66.6 Mo, ce qui met bien en \'evidence la compression de donn\'ee qu'apporte la r\'eduction de mod\`eles. On a trac\'e les 500 premi\`eres valeurs singuli\`eres de M:
	
	\begin{figure}[H]
	\centering
	\includegraphics[width=8cm]{valeurs_singulieres_eulerien_cellulaire.png}
	\caption{Tracé du $\log$ des 500 premi\`eres valeurs singulières}
	\end{figure}
	
	On observe une d\'ecroissance exponentielle des valeurs singuli\`eres, ce qui indique que la POD est une solution envisageable dans le cas des \'ecoulements cellulaires. On peut donc s\'electionner un nouveau jeu de param\`etres "out of data in range", i.e $(x_0, y_0, \theta_0)$ dans $[0.25,0.75]\times [0.25,0.75]\times [0,2.5]$ calculer la solution fine \`a l'aide des volumes finis, puis projeter chaque snapshot sur les $r$ premiers vecteurs de la base POD afin de calculer l'erreur. 
	
	Voici les différentes reconstructions pour un nombre de modes propres valant 10, 20, 50, 100 et 500, pour la condition initiale $(x_0,y_0,\theta_0)=(0.35,0.35,1)$ :
	
	\begin{tabular}{cc}
	\includegraphics[width=0.5\linewidth]{ini_fine.png} &	\includegraphics[width=0.5\linewidth]{ini10modes.png}\\
	Condition initiale de r\'ef\'erence & Condition initiale, 10 modes
	\end{tabular}
	
	\begin{tabular}{cc}
	\includegraphics[width=0.5\linewidth]{ini20modes.png} &	\includegraphics[width=0.5\linewidth]{ini50modes.png}\\
	Condition initiale, 20 modes & Condition initiale, 500 modes
	\end{tabular}
	
	\begin{tabular}{cc}
	\includegraphics[width=0.5\linewidth]{ini100modes.png} &	\includegraphics[width=0.5\linewidth]{ini500modes.png}\\
	Condition initiale, 100 modes & Condition initiale, 500 modes
	\end{tabular}\\
	
	On remarque que la condition initiale "in range" est plut\^ot bien restitu\'ee au bout d'un certain nombre de modes. On remarque de m\^eme, que la projection donne des concentrations n\'egatives et des oscillations \`a certains endroits, ce qui est un inconv\'enient par rapport \`a la m\'ethode des volumes finis qui conserve la positivit\'e de la solution. 
	
	On obtient le m\^eme genre de r\'esultats si on fait de m\^eme pour un snapshot au milieu de la simulation:
		
	\begin{tabular}{cc}
	\includegraphics[width=0.5\linewidth]{fin_fine.png} &	\includegraphics[width=0.5\linewidth]{fin10modes.png}\\
	A mi-parcours, r\'ef\'erence & A mi-parcours, 10 modes
	\end{tabular}
	
	\begin{tabular}{cc}
	\includegraphics[width=0.5\linewidth]{fin20modes.png} &	\includegraphics[width=0.5\linewidth]{fin50modes.png}\\
	A mi-parcours, 20 modes & A mi-parcours, 500 modes
	\end{tabular}
	
	\begin{tabular}{cc}
	\includegraphics[width=0.5\linewidth]{fin100modes.png} &	\includegraphics[width=0.5\linewidth]{fin500modes.png}\\
	A mi-parcours, 100 modes & A mi-parcours, 500 modes
	\end{tabular}\\
	
	\bigskip
	
	Lorsqu'on calcule l'erreur relative en norme de Fr\oe benius, on obtient:
	
	\begin{figure}[H]
	\centering
	\includegraphics[width=8cm]{erreureuleriencellulaire.png}
	\caption{Erreur relative en norme de Fr\oe benius}
	\end{figure}
	
	Cela comfirme bien les observations pr\'ec\'edentes.
	
	Ensuite, on s'est interess\'e \`a des jeux de param\`etres "out of data-out of range ", i.e. $(x_0, y_0, \theta_0)$ en dehors de $[0.25,0.75]\times [0.25,0.75]\times [0,2.5]$. Ainsi, pour $(x_0, y_0, \theta_0)=(0,0,1)$, la gaussienne initiale devient:
	
	\begin{figure}[H]
	\centering
	\includegraphics[width=8cm]{out500modes.png}
	\caption{Projection d'une gaussienne "out of range" pour 500 modes}
	\end{figure}
	
	On observe d\'eja que la gaussienne n'est pas tr\`es bien restitu\'ee. 
	
	Puis, au milieu de la simulation, la projection sur les 500 modes propres n'est pas du tout restitu\'ee:
	
	\begin{figure}[H]
	\centering
	\includegraphics[width=8cm]{outfin.png}
	\includegraphics[width=8cm]{outfin500modes.png}
	\caption{Solution de r\'ef\'erence et sa projection sur 500 modes propres}
	\end{figure}
	
	Cela est du au fait que les modes propres sont quasiment nuls en dehors de l'intervalle $[0.25,0.75]\times [0.25,0.75]\times [0,2.5]$. On constate donc les limites de la m\'ethode POD.
	
	
	
	\subsubsection{Prise en compte de la positivit\'e de la concentration}
	
	Afin de prendre en compte la positivit\'e de la solution, on peut ajuster les coefficients de la POD de sorte \`a ce que:
	
	$$(a_j)_j=\text{argmin} \|c_{*}-\sum\limits_j a_j\varphi_j \|_{L^2} \text{ s.c. } \sum\limits_j a_j\varphi_j\geq0$$ 
	
	Pour cela, nous avons utilis\'e les algorithme d'optimisation de la bibliot\`eque \textbf{scipy.optimize}.\\
	
	Voici un exemple de correction d'une gaussienne projet\'ee sur la base POD:
	
	\begin{figure}[H]
	\centering
	\includegraphics[width=8cm]{opticell2.png}
	\includegraphics[width=8cm]{opticell1.png}
	\caption{Projection d'une gaussienne sur la base propre, et son optimisation}
	\end{figure}
	
	Voici un autre exemple en cours de simulation:
	
	\begin{figure}[H]
	\centering
	\includegraphics[width=8cm]{micheminmode20.png}
	\includegraphics[width=8cm]{micheminmode50.png}
	\caption{Correction d'une gaussienne au cours d'une simulation, pour 20 et 50 modes}
	\end{figure}
	
	Ainsi, cette m\'ethode d'optimisation est plutt\^ot efficace afin de respecter la condition de positivit\'e de la concentration. Cependant, il faut lancer l'algorithme pour chaque snapshot, ce qui rallonge consid\'erablement le temps de calcul, et donc supprime l'avantage principal de la r\'eduction de mod\`ele. 
	
	
	\subsection{Approche Lagrangienne}
	
	\subsubsection{Vitesse constante}
	Voici les valeurs singulières de la matrice des snapshots pour 10 particules. Nous avons également effectué le calcul pour 100 particules,
	le resultat obtenu est le même. 
	\begin{figure}[H]
		\begin{center}
			\includegraphics[scale=0.5]{valeurs_singulieres_cell_10_particules.png}
			\caption{Valeurs singulières pour 10 particules}
		\end{center}
	\end{figure}
	
	
	\begin{figure}[H]
		\begin{center}
			\includegraphics[scale=0.5]{lagrange_gauss_1er_mode.png}
			\caption{Projection suivant le premier mode}
		\end{center}
	\end{figure}
	
	La décroissance des valeurs singulières est très rapide dans les deux cas. Les deux premiers modes propres (colonnes de $U$ suffisent à représenter très correctement
	la solution. 
	Ce résultat était prévisible puisque les particules possèdent des trajectoires rectilignes uniformes, ce qui est relativement simple à representer. 
	
	\subsubsection{Écoulement cellulaire}
	
	La dynamique a été simulée en utilisant les paramètres suivants : $\theta_0 = 0.2;  \theta_1 = 3.12; \theta_2 = 2.69$.
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.5\linewidth]{ecoulement_cellulaire_10}
		\caption{10 particules dans un écoulement cellulaire}
		\label{fig:ecoulementcellulaire10}
	\end{figure}
	
	La figure suivante montre les valeurs singulières de la matrice des snapshots pour 100 particules, pour les paramètres donnés ci-dessus.
	\begin{figure}[H]
		\begin{center}
			\includegraphics[scale=0.5]{valeurs_singulieres_cell_100_particules.png}
			\caption{Valeurs singulières pour 100 particules, 1 simulation}
			\label{valeurs_singulieres_cell_100_particules}
		\end{center}
	\end{figure}
	On remarque que la décroissance est assez lente.
	
	
	La simulation suivante a nécessite plus de temps de calcul. Les positions initiales ainsi que le premier paramètre du modèle sont choisis aléatoirement.
	64 trajectoires ont été simulées, pour 100 particules. Les positions initiales suivent une loi gaussienne centrée en (0.25 , 0.5) et de variance 0.05. 
	Le premier paramètre ($\theta_0$) a été choisi uniformément sur $[0, 2.5]$.
	\begin{figure}[H]
		\begin{center}
			\includegraphics[scale=0.5]{lagrange_cell_variation_parametres.png}
			\caption{Valeurs singulières pour 500 particules, 64 simulations}
			\label{valeurs_singulieres_cell_100_particules}
		\end{center}
	\end{figure}
	
	D'une part, les valeurs singulières sont très élevées et d'autre part, leur décroissance est plutôt lente.
	
	\subsubsection{Champs de Lamb-Oseen}
	Dans cette simulation : $\Gamma = 10$, $\nu = 0.5$ et $r_c = 0.7$.
	Le tourbillon est centré en 0 mais nous n'étudions ici que le domaine $(0,1)^2$.
	\begin{figure}[H]
		\begin{center}
			\includegraphics[scale=0.5]{champ_lamboseen.png}
			\caption{100 particules dans un champs de Lamb-Oseen}
		\end{center}
	\end{figure}
	
	\begin{figure}[H]
		\begin{center}
			\includegraphics[scale=0.5]{valeurs_singulieres_lambo_100_particules.png}
			\caption{Valeurs singulières pour 100 particules}
		\end{center}
	\end{figure}
	
	Comme dans le cas où le champs de vitesse est uniforme, les valeurs singulières de la matrice des snapshots décroissent assez rapidement. 
	
	\section{Discussion} \label{section}
	
	\subsection{Approche Eulerienne}
	
	De manière générale, le schéma de Lax-Frierichs diffuse beaucoup et il faudrait un maillage très fin pour que cela ne soit pas visible sur une grande période de temps. Pour diminuer la diffusion, on peut aussi penser à faire une méthode d'ordre 2 (non-linéaire) qui est liée au schéma de Lax-Friedrichs, mais elle serait plus difficile à implémenter et plus coûteuse en temps. 
	
	\subsubsection{Vitesse constante}
	
	La dynamique de la solution change pour chaque valeur de $\theta$. Il faudrait donc faire beaucoup plus de simulations
	et donc avoir plus de solutions fines pour permettre une bonne réduction (couvrir tout l'espace possible de propagation finalement).\\
	Ceci impliquerait un stockage mémoire encore plus conséquent, et un temps de calcul très grand. Cependant, un nouveau paramètre dans l'intervalle de simulations est plutôt bien reconstruit avec une centaine de modes.\\
	
	Le coût en temps en amont est donc assez conséquent, et on ne peut pas se permettre autant de simulations fines \emph{a priori}. Enfin, on voit que les modes n'oscillent que sur le cadran supérieur droit. Un angle n'étant pas compris dans l'intervalle sera très mal représenté, c'est aussi une limite de l'algorithme POD, exposée notamment dans le cas de l'écoulement cellulaire.\\
	
	Dans le cas d'une vitesse constante, l'approche lagrangienne semble donc plus adaptée.
	
	\subsubsection{\'Ecoulement cellulaire}
	
	Tout comme pour le cas vitesse constante, la dynamique d\'epend tr\`es fortement de la position initiale de la gaussienne ainsi que des param\`etres r\'egissant l'\'ecoulement. Cependant, tant que l'on reste "in range", la base POD arrive \`a bien reconstruire la solution avec un nombre raisonnable de modes propres. On observe les m\^emes limites que dans le cas constant, i.e. que les solutions "out of range" trop \'eloign\'ees du domaine initial ne sont pas tr\`es bien rendues. 
	
	
	
	\subsection{Approche Lagrangienne}
	
	\subsubsection{Vitesse constante}
	
	Cependant, Les modes propres dépendent
	de l'angle $\theta$ qui caractérise la vitesse des particules. Si ce paramètre est modifié alors le mode propre est également modifié.
	L'approche lagrangienne est préferable à l'approche eulerienne dans ce cas.
	
	\subsubsection{Écoulement cellulaire}
	La décroissance des valeurs singulières est assez lente. Un grand nombre de modes propres est donc nécessaire pour donner une 
	bonne approximation de la solution. D'après la figure \ref{valeurs_singulieres_cell_100_particules}, 60 modes propres sont nécessaires pour obtenir
	une erreur de l'ordre de $10^{-3}$.
	De plus, dans la seconde étude, l'approximation n'est donc pas satisfaisante puisque les valeurs singulières sont trop élevées.
	L'approche eulerienne est donc largement préferable dans ce cas de figure. 
	
	\subsubsection{Champ de Lamb-Oseen}
	Un faible nombre de modes propres est par conséquent nécessaire pour obtenir 
	une approximation convenable.
	Ce résultat était prévisible. En effet, la vitesse est uniquement tangentielle, les particules ont donc toutes des trajectoires similaires.
	Les premiers modes propres servent donc à representer ces trajectoires circulaires. Les autres modes propres ne contiennent que peu d'informations.
	Là encore, l'approche lagrangienne est plus efficace et plus précise que l'approche eulerienne.
	
	
	\section{Conclusions}
	
	Tout au long de ce projet, nous avons donc pu observer que la POD, utilisée dans de bonnes conditions, était non seulement un outil fonctionnel mais surtout indispensable 
	pour modéliser des équations telles que l'équation d'advection en des temps de calcul raisonnables. De plus, nous avons montré qu'il était possible de maîtriser les incertitudes 
	en jeu tout en réduisant la taille des données utilisées, en stockant pour cela moins de modes de la POD. \\
	
	En revanche, nous avons déterminé une séparation entre les écoulements pour lesquels l'approche lagrangienne était bien plus adaptée (vitesse constante, Lamb-Oseen) et ceux pour 
	lesquels l'approche eulérienne donnait de meilleurs résultats (écoulement cellulaire). Il est interessant de remarquer que l'approche lagrangienne est plus efficace lorsque les particules posèdent des trajectoires similaires, ce qui n'est pas le cas pour des écoulements cellulaires.
	Nous avons également déterminé ainsi qu'une limitation de l'algorithme dans le cas d'une reconstruction d'une solution fine pour un paramètre n'étant pas dans l'intervalle de départ choisi pour construire la base de modes propres. Ainsi, il semble que la POD demande de bien choisir l'approche choisie en fonction de l'écoulement 
	observé afin d'obtenir une réduction optimale du modèle, et de se poser la question du nombre de simulations (et donc du temps de calcul en amont) et de quels paramètres pertinents choisir pour créer la base de la POD.\\
	
	Enfin, grâce à une interpolation d'ordre 1 d'un champ de vitesse discrétisé, nous avons pu entrevoir comment résoudre et compresser un tel modèle à partir de relevés expérimentaux comme 
	on y serait confronté dans une situation réelle.\\
	
	Ainsi, nous avons remarqué que la réduction de modèles en grande dimension via la POD était une méthode permettant, sous réserve d'un bon 
	choix d'approche et de paramètres, de résoudre rapidement et avec une certaine fiabilité les équations décrivant le transport de polluants.  
	
	
	\section{Appendice}
	
	\subsection{Méthode des volumes finis ~\cite{Cours2}}
	\label{MVF-A}
	Dans le cas de l'approche eulérienne, on utilise un schéma qui est différent de ceux utilisés jusqu'à présent dans nos cours. Détaillons un peu comment cette méthode fonctionne.\\
	
	
	Considérons l'équation de transport dans le cas général en dimension $d>0$ sur un compact en temps et en espace $[0,T]\times [a,b]^d$ pour $T \in \mathbb{R}^*_+$ et $a<b$ dans $\mathbb{R}$
	
	\begin{equation}
	\frac{\partial c}{\partial t} + u \cdot \nabla c = f
	\label{dimd}
	\end{equation}
	
	où $c : [0,T] \times [a,b]^d \longrightarrow [0,1]$ la concentration du polluant, $u : [0,T]\times [a,b]^d \longrightarrow \mathbb{R}^d$ le champ des vitesses imposé dans le milieu et $f : [0,T]\times [a,b]^d \longrightarrow \mathbb{R}$ la source de pollution.\\
	
	Dans notre étude nous prenons $f=0$, nous considérons qu'il n'y a pas de source. \\
	
	\subsubsection{Maillage}
	Nous posons $[a,b] = [0,L]$ afin de simplifier. Maintenant, pour discrétiser l'équation (\ref{dimd}) en espace, nous utilisons deux suites arithmétiques $(x_i)_{i=1}^{n_x}$ sur l'axe des abscisses et $(y_i)_{i=1}^{n_y}$ sur l'axe des ordonnées, vérifiant : 
	
	\begin{equation*}
	\begin{cases}
	x_i = i \Delta x = i \frac{L}{n_x}   \\
	y_i = i \Delta y = i \frac{L}{n_y}   \\
	\end{cases}
	\end{equation*}
	
	On obtient une grille de $(n_x-1)(n_y-1)$ cellules. On appelle alors $K_{i,j}  = [x_i,x_{i+1}] \times [y_j,y_{j+1}]$, et $\Gamma_{i,j}^{k,l} = K_{i,j} \cap K_{k,l}$.\\
	
	On discrétise $[0,T]$ en utilisant la suite $(t_i)_{i=1}^{n_t}$ (qui n'est pas nécessairement arithmétique) vérifiant la condition CFL et : 
	\begin{equation*}
	\begin{cases}
	t_1=0  &  \\
	t_{n_t}=T  \\
	t_i<t_{i+1} \ \forall i < n_t \\
	\end{cases}
	\end{equation*} 
	Ainsi, nous posons pour $1 \leq i \leq n_x$, $1 \leq j \leq n_y$ et $1 \leq n \leq n_t$:: 
	\begin{align*}
	X &= (x,y), \ dX = dxdy \\
	\vert K_{i,j} \vert &= (x_{i+1}-x_i)(y_{j+1}-y_j) = \Delta x \Delta y = \frac{L^2}{n_x n_y}  \\
	c_{i,j}(t_n) &=\frac{1}{\vert K_{i,j} \vert}\int_{K_{i,j}} c(t_n,X) dX,\\ 
	u_{i,j}(t_n) &=\frac{1}{\vert K_{i,j} \vert}\int_{K_{i,j}} u(t_n,X) dX.
	\end{align*}
	
	\subsubsection{Schéma numérique}
	Nous considérons l'équation (\ref{dimd}) dans sa forme faible, c'est à dire au sens des distributions, en utilisons le fait que $\mathrm{div}(c \ u) = u \nabla c + c \ \mathrm{div}(u)$. Nous pouvons la réécrire sous la forme suivante : 
	\begin{equation*}
	\frac{\partial c}{\partial t} + \mathrm{div}(c \ u) -  c \ \mathrm{div}(u) = 0
	\end{equation*}
	Dans notre projet, on considère des vitesse de fluides incompressibles : $\mathrm{div}u=0$. L'équation devient:
	\begin{equation}
	\frac{\partial c}{\partial t} + \mathrm{div}(c \ u) = 0 
	\label{faible}
	\end{equation}
	Maintenant, en fixant $t_n \in [0,T]$, nous intégrons sur chaque cellule $K_{i,j}$,
	\[
	\frac{1}{\vert K_{i,j} \vert}\int_{K_{i,j}} \left( \frac{\partial c}{\partial t} + \mathrm{div}(c \ u) \right) dX = 0 
	\]
	On peut permuter l'intégrale et la dérivation par rapport au temps puisque les cellules $K_{i,j}$ sont indépendantes de temps, et on utilise le théorème de Green pour des fonctions suffisamment régulières :\\ $\int_{\Omega} \mathrm{div} (a) \ d \Omega = \int_{\partial \Omega} a\cdot n \ d\L $ , où $n$ est le vecteur normal sortant. Ainsi:
	\[
	\frac{\partial c_{i,j}}{\partial t}(t_n) +  \frac{1}{\vert K_{i,j} \vert} \int_{\partial K_{i,j} } c \ u \cdot n \ dL = 0\\
	\]
	Chaque cellule est un rectangle, ces bords sont donc des segments et nous posons, pour chaque cellule, $\Gamma$ la quantité $\frac{1}{\vert \Gamma \vert }\int_{\Gamma} c \ u \ dL= F_{\Gamma}(c)$ :
	\[
	\int_{\partial K_{i,j} } c \ u \cdot n \ dL = \sum_{k,l} \vert \Gamma_{i,j}^{k,l} \vert F_{\Gamma_{i,j}^{k,l}}(c) \cdot n_{i,j \rightarrow k,l}
	\]  
	
	Cette somme contient bien sûr quatre termes puisque les cellules sont des rectangles.\\
	
	$F_{\Gamma} \cdot n$ est le flux sortant de la cellule $K_{i,j}$ à partir de la face $\Gamma$, on cherche maintenant à l'approcher numériquement de manière stable, on choisit pour cela un schéma de flux en 2-points, c'est à dire,  
	\[
	F_{ \Gamma_{i,j}^{k,l}}(c) \cdot n_{i,j \rightarrow k,l}  \simeq  g(c_{i,j},c_{k,l})
	\]
	Le flux sortant de $\Gamma$ dépend de la valeur de $c$ dans les deux cellules voisines qui contiennent $\Gamma$.\\
	
	La méthode de Godunov permet de donner une fonction $g$ qui assure la stabilité du schéma. En effet, il propose pour des scalaires $a$ et $b$,  
	$$g(a,b)=F_{ \Gamma_{i,j}^{k,l}} (c_R(t_n,0)) \cdot n_{i,j \rightarrow k,l}$$ 
	où $c_R$ est la solution du problème du Riemann définit par :
	\begin{equation}
	\begin{cases}
	\mathrm{trouver \ c(t,x) \ telle \ que }\\
	\frac{\partial c}{\partial t} + \mathrm{div}(c \ u) = 0 \\
	c(0,x) = a\mathds{1}_{x<0} + b\mathds{1}_{x>0}
	\end{cases}
	\label{R}
	\end{equation}
	mais vu la difficulté de la résolution du problème exact \eqref{R}, nous  utilisons le schéma de Lax-Friedrichs qui peut être considéré comme une méthode approch\'ee de la méthode de Godunov, plus simple à implémenter et rapide :
	\begin{equation}
	\begin{cases}
	\lambda_{i,j \rightarrow k,l} = \mathrm{max}\lbrace u_{i,j}\cdot n_{i,j \rightarrow k,l} , u_{k,l}\cdot n_{i,j \rightarrow k,l} \rbrace \\
	g(c_{i,j},c_{k,l}) = \frac{1}{2} (c_{i,j}u_{i,j} + c_{k,l}u_{k,l})\cdot n_{i,j \rightarrow k,l} + \frac{1}{2\lambda_{i,j \rightarrow k,l}}(c_{i,j} - c_{k,l})
	\end{cases}
	\label{LF}
	\end{equation}
	Il faut noter que le flux que nous avons utilisé $g$ est un flux conservatif c'est à dire 
	$$g(c_{i,j},c_{k,l}) + g(c_{k,l},c_{i,j}) = 0,$$
	ce qui est rassurant vu la nature conservative de l'équation \eqref{faible}.
	
	On utilise pour discrétiser le terme en $\partial_t$ un schéma d'Euler explicite :
	\[
	\frac{\partial c}{\partial t}(t_n) \simeq \frac{c(t_n)-c(t_{n-1})}{t_n-t_{n-1}}
	\]
	Enfin le schéma numérique à implémenter est :\\
	Pour toute cellule $K_{i,j}$
	\begin{equation}
	c_{i,j}(t_n) = c_{i,j}(t_{n-1}) - \frac{t_n-t_{n-1}}{\vert K_{i,j} \vert}  \sum_{k,l} \vert \Gamma_{i,j}^{k,l} \vert g(c_{i,j}(t_{n-1}),c_{k,l}(t_{n-1})) \ \forall n
	\label{SN}
	\end{equation}
	
	
	
	\section{Annexes}
	
	\subsection{Création du maillage}
	
	\lstinputlisting{maillage.py}
	
	\subsection{Approche Eulerienne}
	
	\subsubsection{Calcul du flux : solveur de Lax-Friedrichs Riemann}
	
	\lstinputlisting{riemann_scal.py}
	
	\subsubsection{Volumes finis - cas constant}
	
	\lstinputlisting{volumesfinis_eulerien_constant.py}
	
	\lstinputlisting{EulOpt.py}
	
	\lstinputlisting{CellularFlow.py}
	
	\lstinputlisting{PODcellularflow.py}
	
	\subsubsection{Decomposition SVD}
	
	\lstinputlisting{svd_eulerien_constant.py}
	
	
	\subsection{Approche Lagrangienne}
	
	\subsubsection{Champs de vitesse uniforme}
	
	\lstinputlisting{lagrange_v_cste.py}
	
	\subsubsection{Champs de vitesse issu d'un écoulement cellulaire}
	
	\lstinputlisting{lagrange_ecouleent_cellulaire.py}
	
	\subsubsection{Champs de vitesse de Lamb Oseen}
	
	\lstinputlisting{lagrange_lambo.py}
	
	
	
	\section{Remerciements}
	
	Nous tenons particulièrement à remercier M. Damiano Lombardi et M. Sébastien Boyaval pour leur patience 
	et leur précieuse aide, ainsi que pour toute l'expérience qu'ils nous ont apporté au cours de ce projet. 
	Nous remercions de même l'Ecole Nationale des Ponts et Chaussées pour la mise en \oe{}uvre d'un tel projet et 
	les rencontres organisées avec les intervenants du cours d'ouverture de M. Boyaval et M. Lombardi.
	
	\newpage
	
	\begin{thebibliography}{99}
		
		
		\bibitem{Cours1}
		V. Ehrlacher, S.Boyaval
		\newblock {\em Méthodes numériques pour les problèmes en grande dimension}.
		\newblock Cours de l'École nationale des ponts et chaussées, 2018.
		
		\bibitem{Cours2}
		S.Boyaval
		\newblock{\em Numerical Hydrodynamics for the environment Illustrated by river flows}
		\newblock Cours de l'École nationale des ponts et chaussées, 2018.
		
	\end{thebibliography}
	
\end{document}
